{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_id': 'set_530650', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_530650/set_530650_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_530650'}\n",
      "{'dataset_id': 'set_5306100', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306100/set_5306100_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306100'}\n",
      "{'dataset_id': 'set_5306150', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306150/set_5306150_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306150'}\n",
      "{'dataset_id': 'set_5306200', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306200/set_5306200_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306200'}\n",
      "{'dataset_id': 'set_5306250', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306250/set_5306250_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306250'}\n",
      "{'dataset_id': 'set_5306300', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306300/set_5306300_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306300'}\n",
      "{'dataset_id': 'set_130650', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_130650/set_130650_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_130650'}\n",
      "{'dataset_id': 'set_2306100', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_2306100/set_2306100_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_2306100'}\n",
      "{'dataset_id': 'set_3306150', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_3306150/set_3306150_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_3306150'}\n",
      "{'dataset_id': 'set_4306200', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_4306200/set_4306200_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_4306200'}\n",
      "{'dataset_id': 'set_5306250', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306250/set_5306250_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_5306250'}\n",
      "{'dataset_id': 'set_6306300', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_6306300/set_6306300_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_6306300'}\n",
      "{'dataset_id': 'set_130650', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_130650/set_130650_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_130650'}\n",
      "{'dataset_id': 'set_230650', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_230650/set_230650_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_230650'}\n",
      "{'dataset_id': 'set_330650', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_330650/set_330650_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_330650'}\n",
      "{'dataset_id': 'set_430650', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_430650/set_430650_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_430650'}\n",
      "{'dataset_id': 'set_530650', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_530650/set_530650_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_530650'}\n",
      "{'dataset_id': 'set_630650', 'dataset_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_630650/set_630650_data.h5', 'folder_path': '/pfs/work7/workspace/scratch/ma_elanza-thesislanza/set_630650'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/hpc_mount/dataset_list.pkl'\n",
    "\n",
    "# Open the file in read-binary mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    # Load the dictionary\n",
    "    data_dict = pickle.load(file)\n",
    "\n",
    "# Print the dictionary\n",
    "\n",
    "for dict in data_dict:\n",
    "    print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the cost strucutre and calculate optimal profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Parameters for multi-item newsvendor problem\n",
    "prices = np.array([0.3, 0.5, 0.6, 0.5, 0.5, 0.5]) #price data\n",
    "prices = prices.reshape(6,1)\n",
    "costs = np.array([0.06, 0.06, 0.06, 0.06, 0.06, 0.06]) #cost data\n",
    "costs = costs.reshape(6,1)\n",
    "salvages = np.array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01]) #salvage data\n",
    "salvages = salvages.reshape(6,1)\n",
    "underage_data = prices - costs \n",
    "overage_data = costs - salvages \n",
    "underage_data_single = underage_data[0,0]\n",
    "overage_data_single = overage_data[0,0]\n",
    "\n",
    "\n",
    "\n",
    "alpha_data = np.array([             #alpha data\n",
    "    [0.0, 0.1, 0.05, 0.1, 0.05, 0.1],\n",
    "    [0.15, 0.0, 0.1, 0.05, 0.05, 0.05],\n",
    "    [0.1, 0.2, 0.0, 0.05, 0.1, 0.05],\n",
    "    [0.05, 0.05, 0.05, 0.0, 0.15, 0.2],\n",
    "    [0.1, 0.05, 0.15, 0.2, 0.0, 0.05],\n",
    "    [0.05, 0.1, 0.05, 0.15, 0.1, 0.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def calculate_cochran(X_test, y_test):\n",
    "    # Before calculating means and variances, check if x1 and x2 are empty\n",
    "    if len(x1) == 0 or len(x2) == 0:\n",
    "        print (\"Empty\")\n",
    "        return np.nan, np.nan, np.nan  # Or handle this case as appropriate\n",
    "    \n",
    "\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        if X_test[i, -1] == 1:  # Check if the last column is 1\n",
    "            x1.append(y_test[i])\n",
    "        else:\n",
    "            x2.append(y_test[i])\n",
    "\n",
    "    # Convert lists to numpy arrays if needed\n",
    "    x1 = np.array(x1)\n",
    "    x2 = np.array(x2)\n",
    "\n",
    "    # Calculate means and variances for each study\n",
    "    mean_x1 = np.mean(x1)\n",
    "    variance_x1 = np.var(x1, ddof=1)\n",
    "\n",
    "    mean_x2 = np.mean(x2)\n",
    "    variance_x2 = np.var(x2, ddof=1)\n",
    "\n",
    "    # Combine means and variances\n",
    "    means = np.array([mean_x1, mean_x2])\n",
    "    variances = np.array([variance_x1, variance_x2])\n",
    "\n",
    "    # Step 1: Calculate weights (inverse of variances)\n",
    "    weights = 1 / variances\n",
    "\n",
    "    # Step 2: Calculate the overall weighted effect\n",
    "    weighted_effect = np.sum(weights * means) / np.sum(weights)\n",
    "\n",
    "    # Step 3: Calculate Cochran's Q\n",
    "    Q = np.sum(weights * (means - weighted_effect) ** 2)\n",
    "\n",
    "    # Step 4: Calculate I²\n",
    "    k = len(means)\n",
    "    I2 = max(0, (Q - (k - 1)) / Q) * 100\n",
    "\n",
    "    # Step 5: Calculate p-value for Q\n",
    "    p_value = 1 - chi2.cdf(Q, df=k-1)\n",
    "\n",
    "    return Q, I2, p_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lanza\\.pyenv\\pyenv-win\\versions\\3.11.7\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63578.88\n",
      "5979.119999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lanza\\.pyenv\\pyenv-win\\versions\\3.11.7\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\lanza\\.pyenv\\pyenv-win\\versions\\3.11.7\\Lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\lanza\\.pyenv\\pyenv-win\\versions\\3.11.7\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3747: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\lanza\\.pyenv\\pyenv-win\\versions\\3.11.7\\Lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "c:\\Users\\lanza\\.pyenv\\pyenv-win\\versions\\3.11.7\\Lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from IvsS_Utils import load_generated_data, load_cost_structure, nvps_profit\n",
    "\n",
    "# Max Profit for multi-item newsvendor problem\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/hpc_mount/set_130650_data.h5', multi=True)\n",
    "load_cost_structure(alpha_input=alpha_data, underage_input=underage_data, overage_input=overage_data)\n",
    "max_profit_multi_normal = nvps_profit(y_test,y_test)\n",
    "print(max_profit_multi_normal)\n",
    "\n",
    "# Max Profit for single-item newsvendor problem\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/hpc_mount/set_130650_data.h5', multi=False)\n",
    "load_cost_structure(alpha_input=alpha_data, underage_input=underage_data_single, overage_input=overage_data_single)\n",
    "max_profit_single_normal = nvps_profit(y_test,y_test)\n",
    "Q_0, I2_0, p_0 = calculate_cochran(X_test, y_test)\n",
    "variance_50 = np.var(y_test)\n",
    "print(max_profit_single_normal)\n",
    "\n",
    "# Max Profit for variance increase\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/test/set_5306100_data.h5', multi=False)\n",
    "max_profit_single_var_100 = nvps_profit(y_test,y_test)\n",
    "variance_100 = np.var(y_test)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/test/set_5306150_data.h5', multi=False)\n",
    "max_profit_single_var_150 = nvps_profit(y_test,y_test)\n",
    "variance_150 = np.var(y_test)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/test/set_5306200_data.h5', multi=False)\n",
    "max_profit_single_var_200 = nvps_profit(y_test,y_test)\n",
    "variance_200 = np.var(y_test)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/test/set_5306250_data.h5', multi=False)\n",
    "max_profit_single_var_250 = nvps_profit(y_test,y_test)\n",
    "variance_250 = np.var(y_test)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/test/set_5306300_data.h5', multi=False)\n",
    "max_profit_single_var_300 = nvps_profit(y_test,y_test) \n",
    "variance_300 = np.var(y_test)\n",
    "\n",
    "# Max Profit for heterogenity\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/test/set_4306510_data.h5', multi=False)\n",
    "max_profit_single_het_10 = nvps_profit(y_test,y_test)\n",
    "Q_10, I2_10, p_10 = calculate_cochran(X_test, y_test)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/test/set_4306520_data.h5', multi=False)\n",
    "max_profit_single_het_20 = nvps_profit(y_test,y_test)\n",
    "Q_20, I2_20, p_20 = calculate_cochran(X_test, y_test)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/test/set_4306530_data.h5', multi=False)\n",
    "max_profit_single_het_30 = nvps_profit(y_test,y_test)\n",
    "Q_30, I2_30, p_30 = calculate_cochran(X_test, y_test)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/test/set_4306540_data.h5', multi=False)\n",
    "max_profit_single_het_40 = nvps_profit(y_test,y_test)\n",
    "Q_40, I2_40, p_40 = calculate_cochran(X_test, y_test)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_generated_data(path='C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/test/set_4306550_data.h5', multi=False)\n",
    "max_profit_single_het_50 = nvps_profit(y_test,y_test)\n",
    "Q_50, I2_50, p_50 = calculate_cochran(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def load_metadata(directory):\n",
    "    metadata = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('meta.pkl'):\n",
    "            with open(os.path.join(directory, file_name), 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                metadata.append({\n",
    "                    'file_name': file_name,\n",
    "                    'hyperparameter': data['hyperparameter'],\n",
    "                    'profit': data['profit'],\n",
    "                    'elapsed_time': data['elapsed_time'],\n",
    "                    'peak_memory' : data['peak_memory'],\n",
    "                    'avg_memory': data['avg_memory']\n",
    "                })\n",
    "    return metadata\n",
    "\n",
    "# Directory where the test files are located\n",
    "directory_path = 'C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/hpc_mount/'\n",
    "\n",
    "# Load metadata from all models\n",
    "metadata_list = load_metadata(directory_path)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "df_metadata = pd.DataFrame(metadata_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               file_name  \\\n",
      "0    set_130650_ANN_complex_IOA_meta.pkl   \n",
      "1  set_130650_ANN_complex_SOAnp_meta.pkl   \n",
      "2   set_130650_ANN_complex_SOAp_meta.pkl   \n",
      "3     set_130650_ANN_simple_IOA_meta.pkl   \n",
      "4   set_130650_ANN_simple_SOAnp_meta.pkl   \n",
      "\n",
      "                                    hyperparameter        profit  \\\n",
      "0   [2, 19, 0.03259591854253751, 42, 10, 16, relu]  52604.612790   \n",
      "1  [8, 15, 0.015497711938645823, 18, 10, 16, relu]  61152.380547   \n",
      "2  [8, 15, 0.015497711938645823, 18, 10, 16, relu]  12980.912077   \n",
      "3    [7, 8, 0.09986941432760484, 50, 10, 16, relu]   5215.587519   \n",
      "4   [6, 15, 0.09117597957701895, 29, 10, 16, relu]   5626.292373   \n",
      "\n",
      "   elapsed_time  peak_memory   avg_memory  \n",
      "0    161.687909  1203.960938  1002.794437  \n",
      "1    276.144137  1209.804688  1062.006270  \n",
      "2    303.158436  1209.804688  1062.006270  \n",
      "3    333.363864  2368.179688  1734.291984  \n",
      "4    429.537078  3876.964844  3520.656250  \n"
     ]
    }
   ],
   "source": [
    "print(df_metadata.head())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected code: Specify the full path including the file name and extension\n",
    "df_metadata.to_csv(\"C:/Users/lanza/Master_Thesis_EL/Integrated-vs-Seperated-Master-Thesis/Main/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata.loc[df_metadata['file_name'] == 'set_330650_ANN_complex_IOA_meta.pkl', 'profit'] = 0\n",
    "df_metadata.loc[df_metadata['file_name'] == 'set_230650_ANN_complex_IOA_meta.pkl', 'profit'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lanza\\AppData\\Local\\Temp\\ipykernel_11632\\1547034099.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_simple['relative_profit'] = df_metadata['profit'] / max_profit_single_normal\n",
      "C:\\Users\\lanza\\AppData\\Local\\Temp\\ipykernel_11632\\1547034099.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_complex['relative_profit'] = df_metadata['profit'] / max_profit_multi_normal\n"
     ]
    }
   ],
   "source": [
    "df_simple = df_metadata[df_metadata['file_name'].str.contains('simple')]\n",
    "df_complex = df_metadata[df_metadata['file_name'].str.contains('complex')]\n",
    "\n",
    "df_simple['relative_profit'] = df_metadata['profit'] / max_profit_single_normal\n",
    "df_complex['relative_profit'] = df_metadata['profit'] / max_profit_multi_normal\n",
    "\n",
    "df_simple = df_simple.sort_values(by='relative_profit', ascending=True)\n",
    "df_complex = df_complex.sort_values(by='relative_profit', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple.loc[df_simple['file_name'].str.contains('5306100'), 'relative_profit'] = df_simple['profit'] / max_profit_single_var_100\n",
    "df_simple.loc[df_simple['file_name'].str.contains('5306150'), 'relative_profit'] = df_simple['profit'] / max_profit_single_var_150\n",
    "df_simple.loc[df_simple['file_name'].str.contains('5306200'), 'relative_profit'] = df_simple['profit'] / max_profit_single_var_200\n",
    "df_simple.loc[df_simple['file_name'].str.contains('5306250'), 'relative_profit'] = df_simple['profit'] / max_profit_single_var_250\n",
    "df_simple.loc[df_simple['file_name'].str.contains('5306300'), 'relative_profit'] = df_simple['profit'] / max_profit_single_var_300\n",
    "\n",
    "df_simple.loc[df_simple['file_name'].str.contains('4306510'), 'relative_profit'] = df_simple['profit'] / max_profit_single_het_10\n",
    "df_simple.loc[df_simple['file_name'].str.contains('4306520'), 'relative_profit'] = df_simple['profit'] / max_profit_single_het_20\n",
    "df_simple.loc[df_simple['file_name'].str.contains('4306530'), 'relative_profit'] = df_simple['profit'] / max_profit_single_het_30\n",
    "df_simple.loc[df_simple['file_name'].str.contains('4306540'), 'relative_profit'] = df_simple['profit'] / max_profit_single_het_40\n",
    "df_simple.loc[df_simple['file_name'].str.contains('4306550'), 'relative_profit'] = df_simple['profit'] / max_profit_single_het_50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ann_ioa  ann_soap  ann_soanp   xgb_ioa  xgb_soap  xgb_soanp\n",
      "0  0.872300  0.741169   0.940990  0.988636  0.990013   0.990268\n",
      "1  0.992121  0.996448   0.995735  0.992227  0.986246   0.986111\n",
      "2  0.994047  0.992586   0.992216  0.991890  0.989322   0.989270\n",
      "3  0.998829  0.994716   0.994903  0.997199  0.995715   0.995435\n",
      "4  0.992200  0.994812   0.994451  0.996243  0.994176   0.995497\n"
     ]
    }
   ],
   "source": [
    "# Initialize DataFrame with the correct dtype for relative_profit values\n",
    "df_test = pd.DataFrame(0.0, index=range(5), columns=['ann_ioa', 'ann_soap', 'ann_soanp', 'xgb_ioa', 'xgb_soap', 'xgb_soanp'])\n",
    "\n",
    "# Use .loc for assignments and ensure values are cast to float\n",
    "for i in range(5):\n",
    "    df_test.loc[i, 'ann_ioa'] = df_simple[df_simple['file_name'].str.contains(f'{i+1}30650_ANN_simple_IOA')]['relative_profit'].astype(float).values\n",
    "    df_test.loc[i, 'ann_soap'] = df_simple[df_simple['file_name'].str.contains(f'{i+1}30650_ANN_simple_SOAp')]['relative_profit'].astype(float).values\n",
    "    df_test.loc[i, 'ann_soanp'] = df_simple[df_simple['file_name'].str.contains(f'{i+1}30650_ANN_simple_SOAnp')]['relative_profit'].astype(float).values\n",
    "    df_test.loc[i, 'xgb_ioa'] = df_simple[df_simple['file_name'].str.contains(f'{i+1}30650_XGB_simple_IOA')]['relative_profit'].astype(float).values\n",
    "    df_test.loc[i, 'xgb_soap'] = df_simple[df_simple['file_name'].str.contains(f'{i+1}30650_XGB_simple_SOAp')]['relative_profit'].astype(float).values\n",
    "    df_test.loc[i, 'xgb_soanp'] = df_simple[df_simple['file_name'].str.contains(f'{i+1}30650_XGB_simple_SOAnp')]['relative_profit'].astype(float).values\n",
    "\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ann_ioa  ann_soap  ann_soanp   xgb_ioa  xgb_soap  xgb_soanp  variance\n",
      "0  0.992200  0.994812   0.994451  0.996243  0.994176   0.995497   23.7731\n",
      "1  0.989853  0.984111   0.985079  0.990344  0.984206   0.983690   50.4436\n",
      "2  0.988615  0.982345   0.981734  0.987851  0.978545   0.979641   73.4700\n",
      "3  0.986585  0.977765   0.979033  0.986527  0.978802   0.977544   98.9596\n",
      "4  0.985893  0.981286   0.979029  0.985561  0.984387   0.983935  149.7324\n",
      "5  0.985191  0.977148   0.978496  0.983671  0.971417   0.971127  147.0891\n"
     ]
    }
   ],
   "source": [
    "df_simple_variance = pd.DataFrame(0.0, index=range(6), columns=['ann_ioa', 'ann_soap', 'ann_soanp', 'xgb_ioa', 'xgb_soap', 'xgb_soanp'])\n",
    "\n",
    "# Iterate over each row index\n",
    "for i in range(6):\n",
    "    # For each column, filter the dataframe, convert to float, and assign the value\n",
    "    df_simple_variance.loc[i, 'ann_ioa'] = df_simple[df_simple['file_name'].str.contains(f'5306{i*50+50}_ANN_simple_IOA')]['relative_profit'].astype(float).values\n",
    "    df_simple_variance.loc[i, 'ann_soap'] = df_simple[df_simple['file_name'].str.contains(f'5306{i*50+50}_ANN_simple_SOAp')]['relative_profit'].astype(float).values\n",
    "    df_simple_variance.loc[i, 'ann_soanp'] = df_simple[df_simple['file_name'].str.contains(f'5306{i*50+50}_ANN_simple_SOAnp')]['relative_profit'].astype(float).values\n",
    "    df_simple_variance.loc[i, 'xgb_ioa'] = df_simple[df_simple['file_name'].str.contains(f'5306{i*50+50}_XGB_simple_IOA')]['relative_profit'].astype(float).values\n",
    "    df_simple_variance.loc[i, 'xgb_soap'] = df_simple[df_simple['file_name'].str.contains(f'5306{i*50+50}_XGB_simple_SOAp')]['relative_profit'].astype(float).values\n",
    "    df_simple_variance.loc[i, 'xgb_soanp'] = df_simple[df_simple['file_name'].str.contains(f'5306{i*50+50}_XGB_simple_SOAnp')]['relative_profit'].astype(float).values\n",
    "\n",
    "df_simple_variance['variance'] = [variance_50, variance_100, variance_150, variance_200, variance_250, variance_300]\n",
    "\n",
    "print(df_simple_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ann_ioa  ann_soap  ann_soanp   xgb_ioa  xgb_soap  xgb_soanp\n",
      "0  0.998829  0.994716   0.994903  0.997199  0.995715   0.995435\n",
      "1  0.991578  0.991877   0.992168  0.993388  0.986118   0.985933\n",
      "2  0.995842  0.994810   0.994009  0.995711  0.989278   0.988921\n",
      "3  0.995011  0.994816   0.994009  0.994564  0.992827   0.992054\n",
      "4  0.995041  0.994811   0.994009  0.995518  0.988416   0.988300\n",
      "5  0.993873  0.994813   0.994009  0.995934  0.992630   0.992281\n",
      "6  0.993594  0.994797   0.994009  0.995144  0.990580   0.989405\n"
     ]
    }
   ],
   "source": [
    "df_simple_feature_noise = pd.DataFrame(0.0, index=range(7), columns=['ann_ioa', 'ann_soap', 'ann_soanp', 'xgb_ioa', 'xgb_soap', 'xgb_soanp'])\n",
    "\n",
    "for i in range(7):\n",
    "    x = 3* (2**i)\n",
    "    df_simple_feature_noise.loc[i, 'ann_ioa'] = df_simple[df_simple['file_name'].str.contains(f'4{x}0650_ANN_simple_IOA')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_feature_noise.loc[i, 'ann_soap'] = df_simple[df_simple['file_name'].str.contains(f'4{x}0650_ANN_simple_SOAp')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_feature_noise.loc[i, 'ann_soanp'] = df_simple[df_simple['file_name'].str.contains(f'4{x}0650_ANN_simple_SOAnp')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_feature_noise.loc[i, 'xgb_ioa'] = df_simple[df_simple['file_name'].str.contains(f'4{x}0650_XGB_simple_IOA')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_feature_noise.loc[i, 'xgb_soap'] = df_simple[df_simple['file_name'].str.contains(f'4{x}0650_XGB_simple_SOAp')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_feature_noise.loc[i, 'xgb_soanp'] = df_simple[df_simple['file_name'].str.contains(f'4{x}0650_XGB_simple_SOAnp')]['relative_profit'].astype(float).mean()\n",
    "\n",
    "print(df_simple_feature_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ann_ioa  ann_soap  ann_soanp   xgb_ioa  xgb_soap  xgb_soanp\n",
      "0  0.980734  0.977477   0.979000  0.983421  0.979809   0.979379\n",
      "1  0.983562  0.974038   0.977361  0.983530  0.971002   0.970321\n",
      "2  0.983172  0.976895   0.979573  0.981807  0.958167   0.958715\n",
      "3  0.980752  0.977183   0.979279  0.982614  0.965231   0.964981\n",
      "4  0.979095  0.977223   0.977839  0.982347  0.959647   0.957011\n",
      "5  0.980957  0.977086   0.979103  0.980145  0.967988   0.967823\n",
      "6  0.974475  0.974077   0.975176  0.981120  0.972237   0.972441\n",
      "7  0.976536  0.964164   0.967297  0.979804  0.962150   0.961526\n"
     ]
    }
   ],
   "source": [
    "df_simple_feature_addinfo = pd.DataFrame(0.0, index=range(8), columns=['ann_ioa', 'ann_soap', 'ann_soanp', 'xgb_ioa', 'xgb_soap', 'xgb_soanp'])\n",
    "\n",
    "for i in range(8):\n",
    "    x = 3* (2**i)\n",
    "    df_simple_feature_addinfo.loc[i, 'ann_ioa'] = df_simple[df_simple['file_name'].str.contains(f'4{x}1650_ANN_simple_IOA')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_feature_addinfo.loc[i, 'ann_soap'] = df_simple[df_simple['file_name'].str.contains(f'4{x}1650_ANN_simple_SOAp')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_feature_addinfo.loc[i, 'ann_soanp'] = df_simple[df_simple['file_name'].str.contains(f'4{x}1650_ANN_simple_SOAnp')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_feature_addinfo.loc[i, 'xgb_ioa'] = df_simple[df_simple['file_name'].str.contains(f'4{x}1650_XGB_simple_IOA')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_feature_addinfo.loc[i, 'xgb_soap'] = df_simple[df_simple['file_name'].str.contains(f'4{x}1650_XGB_simple_SOAp')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_feature_addinfo.loc[i, 'xgb_soanp'] = df_simple[df_simple['file_name'].str.contains(f'4{x}1650_XGB_simple_SOAnp')]['relative_profit'].astype(float).mean()\n",
    "\n",
    "print(df_simple_feature_addinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ann_ioa  ann_soap  ann_soanp   xgb_ioa  xgb_soap  xgb_soanp  Cochran´s Q  \\\n",
      "0  0.998829  0.994716   0.994903  0.997199  0.995715   0.995435          NaN   \n",
      "1  0.993791  0.990725   0.990836  0.992319  0.989437   0.988555     0.256819   \n",
      "2  1.259955  1.259884   1.259311  1.260179  1.256513   1.257783     0.124690   \n",
      "3  1.686455  1.661782   1.663185  1.685484  1.671644   1.672425     0.669219   \n",
      "4  2.198819  2.197880   2.196913  2.200236  2.184338   2.184401     1.509492   \n",
      "5  3.084719  3.080806   3.080841  3.084008  3.069115   3.070164     2.786059   \n",
      "\n",
      "          I2   p-value  \n",
      "0   0.000000       NaN  \n",
      "1   0.000000  0.612314  \n",
      "2   0.000000  0.724002  \n",
      "3   0.000000  0.413324  \n",
      "4  33.752544  0.219217  \n",
      "5  64.107001  0.095088  \n"
     ]
    }
   ],
   "source": [
    "df_simple_heterogenity = pd.DataFrame(0.0, index=range(6), columns=['ann_ioa', 'ann_soap', 'ann_soanp', 'xgb_ioa', 'xgb_soap', 'xgb_soanp'])\n",
    "\n",
    "for i in range(6):\n",
    "    df_simple_heterogenity.loc[i, 'ann_ioa'] = df_simple[df_simple['file_name'].str.contains(f'43065{10*i}_ANN_simple_IOA')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_heterogenity.loc[i, 'ann_soap'] = df_simple[df_simple['file_name'].str.contains(f'43065{10*i}_ANN_simple_SOAp')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_heterogenity.loc[i, 'ann_soanp'] = df_simple[df_simple['file_name'].str.contains(f'43065{10*i}_ANN_simple_SOAnp')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_heterogenity.loc[i, 'xgb_ioa'] = df_simple[df_simple['file_name'].str.contains(f'43065{10*i}_XGB_simple_IOA')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_heterogenity.loc[i, 'xgb_soap'] = df_simple[df_simple['file_name'].str.contains(f'43065{10*i}_XGB_simple_SOAp')]['relative_profit'].astype(float).mean()\n",
    "    df_simple_heterogenity.loc[i, 'xgb_soanp'] = df_simple[df_simple['file_name'].str.contains(f'43065{10*i}_XGB_simple_SOAnp')]['relative_profit'].astype(float).mean()\n",
    "\n",
    "df_simple_heterogenity['Cochran´s Q'] = [Q_0, Q_10, Q_20, Q_30, Q_40, Q_50]\n",
    "df_simple_heterogenity['I2'] = [I2_0, I2_10, I2_20, I2_30, I2_40, I2_50]\n",
    "df_simple_heterogenity['p-value'] = [p_0, p_10, p_20, p_30, p_40, p_50]\n",
    "\n",
    "print(df_simple_heterogenity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
